---
title: "Summary of the annual 2018 and 2019 sablefish (*Anoplopoma fimbria*) trap surveys, October 9 - November 19, 2018 and October 8 - November 25, 2019"
year: 2020
report_number: nnn
author: |
  Lisa C. Lacko, 
  Schon M. Acheson and
  Brendan M. Connors
author_list: "Lacko, L.C. and Acheson, S.M. and Connors, B.M."
region: Pacific Region
isbn: ""
address: |
     Pacific Biological Station\
     Fisheries and Oceans Canada, 3190 Hammond Bay Road\
     Nanaimo, British Columbia, V9T 6N7, Canada\
phone: "(555) 555-5555"
author_footnote: "Email: Lisa.Lacko@dfo-mpo.gc.ca | telephone: (250) 756-5555"
abstract: |
  This document describes sampling activities and summarizes results from the 2018 and 2019 British Columbia sablefish research and assessment surveys. It is intended to provide a historical reference for researchers and industry. These annual surveys utilized the same sampling strategies at stratified random (StRS) sites and traditional inlet sites. The random component was comprised of StRS sets at five depth-stratified areas and the traditional component employed standardized sets at four inlet localities on the mainland.
  
  As in previous surveys, biological sampling for sablefish included collection of length, weight, sex, maturity and age structures. Sablefish were randomly sampled from every third trap on all sets, up to a maximum sample size of 60 sablefish. Biological samples (length, weight, sex, maturity and otoliths) were taken for yelloweye rockfish, shortraker rockfish and rougheye/blackspotted rockfish species from all traps. In addition, genetic samples were taken for the rougheye/blackspotted rockfish complex and yelloweye rockfish. Length and weight measurements were collected from all Pacific halibut and lengths were obtained from Pacific sleeper sharks. The tag and release study has been conducted annually since 1991 and was continued in 2018 and 2019. Sablefish were selected randomly for tag and release from every third trap up to a maximum of 125 fish. 
  
  In total, 58,415 sablefish were caught in 2018, of which 5,741 were used for biological samples and 10,965 were tagged and released. Of those released, 213 were recaptured tagged fish. Five recaptured fish were retained for samples and the remaining 208 were fitted with a new tag and released back into the water. In 2019, a total of 78,836 sablefish were caught, of which 5,659 were used for biological samples and 12,042 were tagged and released. Of those released, 156 were recaptured tagged fish. Two recaptured fish were retained for samples and the remaining 154 were fitted with a new tag and released.
  
  Catch per unit effort (CPUE) is an important result from this survey as it is used to infer population trends. In most recent years, survey data from StRS sets show increasing trends in both mean weight and numbers of fish per trap. CPUE at traditional inlet sites have varied in a predictable manner over time with peak CPUE occurring every 5-8 years and increasing to record levels in 2018 and 2019. At both StRS and traditional inlet sites, the average weight of sablefish in 2018 and 2019 reached record mean lows due to large numbers of small fish.

  
abstract_other: |
  Le présent document décrit les activités d’échantillonnage et résume les résultats des relevés de recherche et d’évaluation de la morue charbonnière menées en Colombie-Britannique en 2018 et 2019. Il vise à fournir une référence historique aux chercheurs et à l’industrie. Ces relevés annuels utilisaient les mêmes stratégies d’échantillonnage aux sites aléatoires stratifiés et aux sites traditionnels des bras de mer. La composante aléatoire était composée d’ensembles de sites aléatoires stratifiés dans cinq zones stratifiées en fonction de la profondeur, tandis que la composante traditionnelle était composée d’ensembles normalisés à quatre bras de mer continentaux.

  Comme dans les relevés précédents, l’échantillonnage biologique de la morue charbonnière comprenait la sélection de la longueur, du poids, du sexe, de la maturité et des structures selon l’âge. Les morues charbonnières ont été échantillonnées de façon aléatoire dans un casier sur trois, jusqu’à une taille d’échantillonnage maximale de 60 morues charbonnières. Dans tous les casiers, des échantillons biologiques (longueur, poids, sexe, maturité et otolites) ont été prélevés pour le sébaste aux yeux jaunes, le sébaste boréal, et le complexe du sébaste à œil épineux et du sébaste à taches noires. De plus, des échantillons génétiques ont été prélevés pour le complexe du sébaste à œil épineux et du sébaste à taches noires et pour le sébaste aux yeux jaunes. Des mesures de la longueur et du poids ont été prises pour tous les flétans du Pacifique, et les longueurs de toutes les laimargues du Pacifique ont été mesurées. L’étude de marquage avec remise à l’eau est menée chaque année depuis 1991, et s’est poursuivie en 2018 et 2019. Les morues charbonnières ont été sélectionnées de façon aléatoire pour l’étude dans un casier sur trois, jusqu’à un maximum de 125 poissons.

  Au total, 58 415 morues charbonnières ont été capturées en 2018, dont 5 741 ont servi à prélever des échantillons biologiques et 10 965 ont été marquées et remises à l’eau. Parmi ces morues charbonnières remises à l’eau, 213 étaient des poissons marqués recapturés. Cinq poissons recapturés ont été conservés aux fins d’échantillonnage, alors que les 208 autres poissons ont été équipés d’une autre étiquette et remis à l’eau. En 2019, un total de 78 836 morues charbonnières ont été capturées, dont 5 659 ont servi à prélever des échantillons biologiques et 12 042 ont été marquées et remises à l’eau. Parmi ces morues charbonnières remises à l’eau, 156 étaient des poissons marqués recapturés. Deux poissons recapturés ont été conservés aux fins d’échantillonnage, alors que les 154 autres poissons ont été équipés d’une autre étiquette et remis à l’eau.

  Les captures par unité d’effort (CPUE) sont un important résultat de ce relevé; elles sont utilisées pour déduire les tendances démographiques. Au cours des dernières années, les données tirées des relevés pour les ensembles aux sites aléatoires stratifiés démontrent des tendances à la hausse en ce qui a trait au poids moyen et au nombre de poissons par casier. Les CPUE aux sites traditionnels des bras de mer varient de façon prévisible au fil du temps et atteignent un sommet tous les 5 à 8 ans; elles ont atteint des sommets records en 2018 et 2019. Aux sites aléatoires stratifiés et aux sites traditionnels, le poids moyen des morues charbonnières en 2018 et 2019 a atteint un creux record en raison du grand nombre de petits poissons.

output:
 csasdown::techreport_pdf:
   french: false
type:
  techreport
# ------------
# End of options to set
knit: bookdown::render_book
site: bookdown::bookdown_site
link-citations: true
bibliography: bib/refs.bib
csl: csl/csas.csl
lot: true
lof: true
# Any extra LaTeX code for the header:
# header-includes:
# - \usepackage{tikz}
header-includes: \usepackage{pdflscape}
                 
---

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir  <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type    <- "png"
} else {
  knitr_figs_dir  <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type    <- "png"
}
fig_asp   <- 0.618
fig_width <- 9
fig_out_width <- "6in"
fig_dpi   <- 180
fig_align <- "center"
fig_pos   <- "htb"
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  #  autodep = TRUE,
  #  cache = TRUE,
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
options(xtable.comment = FALSE)
options(kableExtra.latex.load_packages = FALSE)
```

```{r load-libraries, cache=FALSE}
# add other packages here:
library(csasdown)
message("year = ", rmarkdown::metadata$year)
#browser()
yr  <-  2018
library(RODBC)
library(knitr)
library(magick)
library(excelR)
library(gapminder)
library(ggplot2)
library(dplyr)        # transform and summarize tabular data
library(xtable)       # produces tables
library(kableExtra)   # produces html tables with scrollbars, etc
library(pacman)       # produces numbered tables and figures in order to reference them
 #  if (!require("pacman")) install.packages("pacman")
 #  pacman::p_load(knitr, captioner, bundesligR, stringr)
library(bookdown)
library(tableHTML)
library(Rmisc)
library(cowplot)
#  ----   G L O B A L --- F U N C T I O N S ---------------------------------
  GetSQLData <- function(strSQL,strDbName) {    # connect to SQL Server
         cnn <- odbcDriverConnect(paste("Driver={SQL Server};Server=DFBCV9TWVASP001;", 
                                         "Database=",
                                          strDbName,";
                                          Trusted_Connection=Yes",
                                          sep=""))
            dat <- sqlQuery(cnn, strSQL)
            odbcClose(cnn)
            return(dat) 
                                            }
  
  panLab <- function( x, y, txt, ... ) { # Allows text to be placed at 0<x<1, 0<y<1)
            usr <- par( "usr" )
            par( usr=c(0,1,0,1) )
            text( x, y, txt, ... )
            par( usr=usr )
            #return( NULL )
            }
  
  cleanf <- function(x){                            # function to remove duplicates
            oldx <- c(FALSE, x[-1]==x[-length(x)])  # is value equal to previous value
            res <- x
            res[oldx] <- NA
            return(res)
            } 
  
  simpleCap <- function(x) {  # add capital first letter to each word
            s <- strsplit(x, " ")[[1]]
            paste(toupper(substring(s, 1,1)), substring(s, 2),
            sep="", 
            collapse=" ")
            }
  
  firstup <- function(x) {   # add capital first letter to first word
            substr(x, 1, 1) <- toupper(substr(x, 1, 1))
            x
  }
  
  format_cells <- function(df, rows ,cols, value = c("italics", "bold", "strikethrough")){
            # select the correct markup
            map    <- setNames(c("*", "**", "~~"), c("italics", "bold", "strikethrough"))
            markup <- map[value]  
            
            for (r in rows){
                  for(c in cols){
                      df[[c]] <- as.character( df[[c]])  # -- make sure values not factors
                      df[r, c] <- paste0(markup, df[r, c], markup)  # -- Update formatting
                                }
                           }
                     return(df)
            }
            
  fig_label <- function(text, region="figure", pos="topleft", cex=NULL, ...) {
           
            region <- match.arg(region, c("figure", "plot", "device"))
            pos    <- match.arg(pos,    c("topleft",    "top", "topright", 
                                          "left",       "center", "right", 
                                          "bottomleft", "bottom", "bottomright"))
           
            if(region %in% c("figure", "device")) {
              ds <- dev.size("in")
              # xy coordinates of device corners in user coordinates
              x <- grconvertX(c(0, ds[1]), from="in", to="user")
              y <- grconvertY(c(0, ds[2]), from="in", to="user")
           
              # fragment of the device we use to plot
              if(region == "figure") {
                # account for the fragment of the device that 
                # the figure is using
                fig <- par("fig")
                dx <- (x[2] - x[1])
                dy <- (y[2] - y[1])
                x <- x[1] + dx * fig[1:2]
                y <- y[1] + dy * fig[3:4]
              } 
            }
           
            # much simpler if in plotting region
            if(region == "plot") {
              u <- par("usr")
              x <- u[1:2]
              y <- u[3:4]
            }
           
            sw <- strwidth(text, cex=cex) * 60/100
            sh <- strheight(text, cex=cex) * 60/100
           
            x1 <- switch(pos,
              topleft     =x[1] + sw, 
              left        =x[1] + sw,
              bottomleft  =x[1] + sw,
              top         =(x[1] + x[2])/2,
              center      =(x[1] + x[2])/2,
              bottom      =(x[1] + x[2])/2,
              topright    =x[2] - sw,
              right       =x[2] - sw,
              bottomright =x[2] - sw)
           
            y1 <- switch(pos,
              topleft     =y[2] - sh,
              top         =y[2] - sh,
              topright    =y[2] - sh,
              left        =(y[1] + y[2])/2,
              center      =(y[1] + y[2])/2,
              right       =(y[1] + y[2])/2,
              bottomleft  =y[1] + sh,
              bottom      =y[1] + sh,
              bottomright =y[1] + sh)
           
            old.par <- par(xpd=NA)
            on.exit(par(old.par))
           
            text(x1, y1, text, cex=cex, ...)
            return(invisible(c(x,y)))
}
  
```

```{r, echo=FALSE}
   inline_hook <- function(x) {  # -- for inline text where numbers are larger 
      if (is.numeric(x)) {
            format(x, digits = 2)
                         } else x
      }
  knitr::knit_hooks$set(inline = inline_hook)
```

```{r SurveyDetails, echo=FALSE}  
   # -- GLOBAL DETAILS FROM SQL SERVER QUERIES/STAND ALONE CSV FILES--
   details     <- paste("select VESSEL_NAME as Vessel, CAPTAIN, ",
                        "LEFT(CONVERT(varchar, START_DATE, 100), 7) + ' - ' ",
                        "+ LEFT(CONVERT(varchar, END_DATE, 100), 7) AS [Trip Dates], ",
                        "COUNT([SET]) AS [Count of Sets] ",
                        "from  dbo.GFBIO_RESEARCH_TRIPS ",
                        "where year IN( ", yr ,",", yr + 1 ,") ", 
                        "group by ",
                        "VESSEL_NAME, CAPTAIN,  ",
                        "LEFT(CONVERT(varchar, START_DATE, 100),7) + ' - ' + ",
                        "LEFT(CONVERT(varchar, END_DATE, 100),7)", 
                         sep="")
   #sd          <- GetSQLData(details,"Sablefish")  # -- survey details query SQL Server
   sd     <- read.csv("c:/github/surveyreport/standaloneData/index1.csv",header=T)  
   
   boat        <- simpleCap(tolower(sd[1,1]))      # -- vessel name year 1
   boat2       <- simpleCap(tolower(sd[2,1]))      # -- vessel name year 2
   
   captain     <- simpleCap(tolower(sd[1,2]))      # -- captain name year 1
   captain2    <- simpleCap(tolower(sd[2,2]))      # -- captain name year 2
   captain2    <- "Albert (Deacon) Melnychuk"
   
   dates       <- sd[1,3]           # -- survey start and end dates year 1
   dates2      <- sd[2,3]           # -- survey start and end dates year 2
   
   setcnt      <- sd[1,4]           # -- survey set count year 1
   setcnt2     <- sd[2,4]           # -- survey set count year 2
   
   avgC        <- paste("select ROUND(AVG(TOTAL), 0) AS YrAvg ",
                        "from   dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",
                        "where (year <= ", yr+1, ") and (year >= ",yr - 8,")", sep="")
   #avgTen     <- GetSQLData(avgC,"Sablefish")    # -- average catch last 10 years query SQL Server              
   avgTen      <- read.csv("c:/github/surveyreport/standaloneData/index2.csv",header=T)
   
   tp          <- paste("select  ROUND(TRAP / TOTAL * 100, 0) AS TrapPer ",
                        "from    dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",  
                        "where  (year = ", yr, ")  group by ROUND(TRAP / TOTAL * 100, 0), TOTAL", sep="")
   #trapP     <- GetSQLData(tp,"Sablefish")        # -- trap gear catch ratio year 1
   trapP      <- read.csv("c:/github/surveyreport/standaloneData/index3.csv",header=T)
   
   lp          <- paste("select  ROUND(LONGLINE / TOTAL * 100, 0) AS LonglinePer ",  
                         "from   dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2  ",
                         "where  (year = ", yr, ") group by ROUND(LONGLINE / TOTAL * 100, 0), TOTAL", sep="")
   #LonglineP  <- GetSQLData(lp,"Sablefish")        # -- longline gear catch ratio year 1
   LonglineP   <- read.csv("c:/github/surveyreport/standaloneData/index4.csv",header=T)
   
   tp2         <- paste("select  ROUND(TRAP / TOTAL * 100, 0) AS TrapPer ",
                        "from    dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",  
                        "where  (year = ", yr + 1, ")  group by ROUND(TRAP / TOTAL * 100, 0), TOTAL", sep="")
   #trapP2     <- GetSQLData(tp2,"Sablefish")      # -- trap gear catch ratio year 2
   trapP2      <- read.csv("c:/github/surveyreport/standaloneData/index5.csv",header=T)
   
   lp2         <-  paste("select  ROUND(LONGLINE / TOTAL * 100, 0) AS LonglinePer  ",  
                         "from    dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2  ",
                         "where  (year = ", yr + 1, ") group by ROUND(LONGLINE / TOTAL * 100, 0), TOTAL", sep="")
   #LonglineP2 <- GetSQLData(lp2,"Sablefish")      # -- longline gear catch ratio  year 2
   LonglineP2  <- read.csv("c:/github/surveyreport/standaloneData/index6.csv",header=T)
   
   # -- F I G U R E   C A P T I O N S  function ------------------------------------------------
   figure_nums <-  captioner::captioner(prefix = "Figure")
   fg.ref      <-  function(x) {    # another method on how to number figures
                                     stringr::str_extract(figure_nums(x), "[^.]*")}
```